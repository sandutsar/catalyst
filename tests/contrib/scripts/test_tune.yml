study:
  _target_: optuna.create_study
  storage: null
  sampler: null
  pruner: null
  study_name: null
  direction: minimize
  load_if_exists: false
  _mode_: call

runner:
  _target_: catalyst.runners.SupervisedRunner
  model:
    _var_: model
    _target_: tests.contrib.scripts.test_tune.CustomModule
    in_features: 784  # 28 * 28
    num_hidden:
      _var_: trial.suggest_int
      name: num_hidden
      low: 32
      high: 128
    out_features: 10
  input_key: features
  output_key: logits
  target_key: targets
  loss_key: loss

run:
  - _call_: train

    criterion:
      _target_: torch.nn.CrossEntropyLoss

    optimizer:
      _target_: torch.optim.Adam
      params:
        _var_: model.parameters
      lr: 0.02

    loaders:
      train:
        _target_: torch.utils.data.DataLoader
        dataset:
          _target_: catalyst.contrib.datasets.MNIST
          root: tests
          train: y
        batch_size: 32
      valid:
        _target_: torch.utils.data.DataLoader
        dataset:
          _target_: catalyst.contrib.datasets.MNIST
          root: tests
          train: n
        batch_size: 32

    callbacks:
      - _target_: catalyst.callbacks.AccuracyCallback
        input_key: logits
        target_key: targets
        topk: [1,3,5]
      - _target_: catalyst.callbacks.PrecisionRecallF1SupportCallback
        input_key: logits
        target_key: targets
        num_classes: 10

    num_epochs: 1
    logdir: tests/logs  # TODO: use `tempfile.TemporaryDirectory`
    valid_loader: valid
    valid_metric: loss
    minimize_valid_metric: y
    verbose: n
    load_best_on_end: y
    timeit: n
    check: n
    overfit: n
